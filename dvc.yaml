stages:
  collecting:
    cmd: jupyter nbconvert --to python --execute nbs/00_Collecting_Data.ipynb --output
      ../scripts/00_Collecting_Data
    deps:
    - pdm.lock
    - pyproject.toml
    - nbs/00_Collecting_Data.ipynb
    - data/raw-data
    outs:
    - scripts/00_Collecting_Data.py
    - data/working-data/Concatenated_Orig_data.csv
  cleaning:
    cmd: jupyter nbconvert --to python --execute nbs/01_Cleaning_Data.ipynb --output
      ../scripts/01_Cleaning_Data
    deps:
    - pdm.lock
    - pyproject.toml
    - nbs/01_Cleaning_Data.ipynb
    - data/working-data/Concatenated_Orig_data.csv
    - data/raw-data/AIDCODE.csv
    outs:
    - scripts/01_Cleaning_Data.py
    - data/cleaned-data/Concatenated_Clean_data.csv
  nn-preprocess:
    cmd: jupyter nbconvert --to python --execute nbs/02a_NN_Preprocessing.ipynb --output
      ../scripts/02a_NN_Preprocessing
    deps:
    - pdm.lock
    - pyproject.toml
    - nbs/02a_NN_Preprocessing.ipynb
    - data/cleaned-data/Concatenated_Clean_data.csv
    outs:
    - scripts/02a_NN_Preprocessing.py
    - data/processed-data/nn/train/FAA-1.csv
    - data/processed-data/nn/test/FAA-1.csv
    - data/processed-data/nn/val/FAA-1.csv
    - data/processed-data/nn/actual/FAA-1.csv
  nn-training:
    cmd: jupyter nbconvert --to python --execute nbs/03a_Training_Model.ipynb --output
      ../scripts/03a_Training_Model
    deps:
    - pdm.lock
    - pyproject.toml
    - nbs/03a_Training_Model.ipynb
    - data/processed-data/nn/train/FAA-1.csv
    - data/processed-data/nn/test/FAA-1.csv
    - data/processed-data/nn/val/FAA-1.csv
    outs:
    - output/model/
    - scripts/03a_Training_Model.py
  classification-preprocess:
    cmd: jupyter nbconvert --to python --execute nbs/02b_Classification_Preprocessing.ipynb
      --output ../scripts/02b_Classification_Preprocessing
    deps:
    - data/cleaned-data/Concatenated_Clean_data.csv
    - nbs/02b_Classification_Preprocessing.ipynb
    - pdm.lock
    - pyproject.toml
    outs:
    - data/cleaned-data/19_features.csv
    - data/cleaned-data/Encoded_Features.csv
    - scripts/02b_Classification_Preprocessing.py
  exp:
    cmd: >
        papermill 
        nbs/exp.ipynb 
        scripts/exp.ipynb
        -p TOKENIZER ${exp.tokenizer}
        -p LEARNING_RATE ${exp.learning_rate}
        -p BATCH_SIZE ${exp.batch_size}
        -p EPOCHS ${exp.epochs}
    deps:
    - nbs/exp.ipynb
    - Text_label_data_c119.csv
    - pdm.lock
    - pyproject.toml
    outs:
    - training/plots:
        persist: true
    metrics:
    - training/metrics.json:
        persist: true
        cache: false
plots:
  - Confusion matrix:
      template: confusion
      x: actual
      y:
        training/plots/sklearn/confusion_matrix.json: predicted
