{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38ee708c-071b-4e87-b170-8b9595face42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# This notebook is an outline for 10 fold cross validation neural network\n",
    "\n",
    "# Environment Setup\n",
    "#! pdm add transformers\n",
    "#! pdm add datasets\n",
    "#! pdm add keras==2.6.*\n",
    "#! pdm add torch==1.8.0 torchtext==0.9.0\n",
    "#! pdm add torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e159a8-6d54-4531-85bb-e37b68f6022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs', '/opt/anaconda3/lib/python39.zip', '/opt/anaconda3/lib/python3.9', '/opt/anaconda3/lib/python3.9/lib-dynload', '', '/afs/crc.nd.edu/user/p/painswor/.local/lib/python3.9/site-packages', '/opt/anaconda3/lib/python3.9/site-packages', '/opt/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/afs/crc.nd.edu/user/p/painswor/.ipython', '../__pypackages__/3.9/lib/']\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import sys\n",
    "sys.path.append('../__pypackages__/3.9/lib/')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3cf50c2b-1ff8-4da2-8b2d-a3b426975fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "import torch\n",
    "#from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000aad-f505-4e3e-969e-cfb514452c87",
   "metadata": {},
   "source": [
    "# Selecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35153cc-1a05-47d0-98cb-17e3bef7db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec59582-d437-43d2-9037-c5b62dfd772c",
   "metadata": {},
   "source": [
    "First lets define where our data is located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5eff39-44a0-4ca8-ac53-1fb270dc466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = '../data/cleaned-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1f7ad-19b3-4de2-b95b-3d146aa29b2c",
   "metadata": {},
   "source": [
    "Now we can import our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2293639-ea7f-4370-9860-62ec87619cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2763, 34)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(f'{cleaned_data}/Maintenance_Text_data.csv')\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a31e6-bf4d-4aea-84fc-adcf1c000c98",
   "metadata": {},
   "source": [
    "Select the columns of relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbfbf795-ddaa-4edf-aaf2-72b110d0eae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAILWHEEL COCKED RIGHT PRIOR TO TKOF.         ...</td>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOW PLANE BECAME AIRBORNE THEN SETTLED.STUDENT...</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ND ILS APCH,ACFT'S G/S INOP.LOM TUNED TO WRON...</td>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLT NOTED SOFT R BRAKE PEDAL DRG TAXI TO TKOF....</td>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAXI OFF HARD SFC DUE TFC R MAIN GR BROKE THRO...</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>(-23) A/C RELOCATED TO NEW HANGAR TO CHECK SIZ...</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>(-23) ON 2/23/08 @ APPROXIMATELY 2130 DURING T...</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>(-23) PILOT TOOK OFF FOR LEESBURG AIRPORT AND ...</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>(-23) OWNER FORGOT TO FASTEN THE LOWER LEFT 4 ...</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>(-23) THE AIRCRAFT EXPERIENCED SEVERE TURBULAN...</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2763 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     TAILWHEEL COCKED RIGHT PRIOR TO TKOF.         ...    AU\n",
       "1     TOW PLANE BECAME AIRBORNE THEN SETTLED.STUDENT...    ME\n",
       "2     2ND ILS APCH,ACFT'S G/S INOP.LOM TUNED TO WRON...    AU\n",
       "3     PLT NOTED SOFT R BRAKE PEDAL DRG TAXI TO TKOF....    AU\n",
       "4     TAXI OFF HARD SFC DUE TFC R MAIN GR BROKE THRO...    AF\n",
       "...                                                 ...   ...\n",
       "2758  (-23) A/C RELOCATED TO NEW HANGAR TO CHECK SIZ...    II\n",
       "2759  (-23) ON 2/23/08 @ APPROXIMATELY 2130 DURING T...    AF\n",
       "2760  (-23) PILOT TOOK OFF FOR LEESBURG AIRPORT AND ...    II\n",
       "2761  (-23) OWNER FORGOT TO FASTEN THE LOWER LEFT 4 ...    II\n",
       "2762  (-23) THE AIRCRAFT EXPERIENCED SEVERE TURBULAN...    ME\n",
       "\n",
       "[2763 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = raw_data['c119']\n",
    "df['label'] = raw_data['c78']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56508453-68c4-4e2f-a00a-94e43c667285",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e697a-e794-465b-a545-edf61c49eb45",
   "metadata": {},
   "source": [
    "Check which columns contain NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "811ecbb2-31c0-4627-96e4-d399d4e92005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     15\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2761c01e-cc16-4c95-b8cc-bcd26e8578a2",
   "metadata": {},
   "source": [
    "Remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953e5308-97fc-4029-bcbc-b3efc3a81a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('Null')\n",
    "df = df[df['text'] != 'Null']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f6c7b0-e100-4ef8-917c-e60198142247",
   "metadata": {},
   "source": [
    "Check there are no missing values left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7022076-29d4-405f-bc87-8eedc15891f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81291f-5de8-4ffd-81e2-0c4b050799c1",
   "metadata": {},
   "source": [
    "Get a quick summary of all non-numeric columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4250d545-5ac1-497e-9577-bc2f3b95deb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2748</td>\n",
       "      <td>2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2742</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>FORCED LANDING AFTER POWER LOSS. FOUND WATER I...</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "count                                                2748  2748\n",
       "unique                                               2742     8\n",
       "top     FORCED LANDING AFTER POWER LOSS. FOUND WATER I...    II\n",
       "freq                                                    4  1942"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4959987a-e26e-47fb-a620-b4a13b6543ad",
   "metadata": {},
   "source": [
    "Remove rows with one occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7da148d2-b03d-4ff0-a2b8-02295cbd1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['label'].value_counts()\n",
    "df = df[df['label'].isin(counts[counts > 1].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f5484-34b6-4836-bd9e-b8b88e9e1c3b",
   "metadata": {},
   "source": [
    "## Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bff35846-b000-4c50-b86c-2bb5ce757098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85e7a3d4-a631-4751-8b2e-2d938853007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StratifiedShuffleSplit(n_splits=10, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31402313-f2b7-449e-9d2b-7cb685bc4c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.get_n_splits(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cb093cb-4f6e-4482-86d5-bfb41dea20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[\"text\"], df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ddaff2fd-889e-4320-9be5-bc1b3bea8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(ss.split(X, y)):\n",
    "    X_train , X_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train , y_test = y.iloc[train_index] , y.iloc[test_index]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.20, random_state=0)\n",
    "    \n",
    "    Encoder = LabelEncoder()\n",
    "    y_train = Encoder.fit_transform(y_train)\n",
    "    y_test = Encoder.fit_transform(y_test)\n",
    "    y_val_encode = Encoder.fit_transform(y_val)\n",
    "    \n",
    "    final_train = pd.DataFrame({'text':X_train,'label':y_train})\n",
    "    final_test = pd.DataFrame({'text':X_test,'label':y_test})\n",
    "    final_val = pd.DataFrame({'text':X_val,'label':y_val_encode})\n",
    "    \n",
    "    final_train.to_csv(f'{cleaned_data}/train/FAA-{i}.csv', index=False)\n",
    "    final_test.to_csv(f'{cleaned_data}/test/FAA-{i}.csv', index=False)\n",
    "    final_val.to_csv(f'{cleaned_data}/val/FAA-{i}.csv', index=False)\n",
    "    y_val.to_csv(f'{cleaned_data}/actual/FAA-{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d34fc6-1d4e-47ee-89c6-d90663e1b1d1",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6e52cf-0b68-4ac7-9f91-d423923fc07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e4aed-c2cb-4831-a668-cc6d3e758e81",
   "metadata": {},
   "source": [
    "Create a dataset from our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4786dcac-76df-4cfa-a9b4-050747a9354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FORCED LANDING AFTER POWER LOSS. HELICOPTER HA...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOSE CARGO COMPARTMENT DOOR CAME OPEN ON TAKEO...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(-23) PRIOR TO TAXI AND TAKEOFF THE PILOT FAIL...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-23) THE PILOT OF N17655 BE-55 DECLARED AN EM...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-23) AMERICAN TRANS AIR, INC. FLIGHT 253 WAS ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>MAINT NOT PERFORMED DUE PARTS NOT AVAILABLE. T...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>AIRCRAFT FAILED PRESSURIZE ON CLIMB OUT. RETUR...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>LANDED DEEP GRASS. FIRE ERUPTED UNDER THE 206L...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>FORCED LANDING AFTER ENGINE QUIT. FOUND FROZEN...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>PILOT STRUCK WIRES AFTER ENGINE STOPPED AND ST...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1757 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     FORCED LANDING AFTER POWER LOSS. HELICOPTER HA...      5\n",
       "1     NOSE CARGO COMPARTMENT DOOR CAME OPEN ON TAKEO...      5\n",
       "2     (-23) PRIOR TO TAXI AND TAKEOFF THE PILOT FAIL...      5\n",
       "3     (-23) THE PILOT OF N17655 BE-55 DECLARED AN EM...      5\n",
       "4     (-23) AMERICAN TRANS AIR, INC. FLIGHT 253 WAS ...      3\n",
       "...                                                 ...    ...\n",
       "1752  MAINT NOT PERFORMED DUE PARTS NOT AVAILABLE. T...      2\n",
       "1753  AIRCRAFT FAILED PRESSURIZE ON CLIMB OUT. RETUR...      5\n",
       "1754  LANDED DEEP GRASS. FIRE ERUPTED UNDER THE 206L...      6\n",
       "1755  FORCED LANDING AFTER ENGINE QUIT. FOUND FROZEN...      5\n",
       "1756  PILOT STRUCK WIRES AFTER ENGINE STOPPED AND ST...      5\n",
       "\n",
       "[1757 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{cleaned_data}/train/FAA-0.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41f01750-e09c-4253-a2a2-684e719b33e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1757, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100cc6a-17a2-4e11-8a05-219f2791a8d1",
   "metadata": {},
   "source": [
    "Tokenize text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3901a18d-594c-4ca9-82b3-60c74aea77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087bf120-a592-494e-8881-9a1cd07b6626",
   "metadata": {},
   "source": [
    "Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9e6ba0f-e2d4-4e67-9605-147cc9dce617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /afs/crc.nd.edu/user/p/painswor/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /afs/crc.nd.edu/user/p/painswor/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt\n",
      "loading file tokenizer.json from cache at /afs/crc.nd.edu/user/p/painswor/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /afs/crc.nd.edu/user/p/painswor/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /afs/crc.nd.edu/user/p/painswor/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb41ad-7473-4699-8db0-3580baca8546",
   "metadata": {},
   "source": [
    "Tokenize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8c182a10-dea3-4caa-be8c-aaeda824793b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc07c4255c9453980ecbbd456f6638e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tok_func(x):\n",
    "    return tokz(x[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tok_ds = ds.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683c425b-5f67-4d18-9f48-24bc98aba656",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47f29486-3610-4c28-9179-67ffbbf8a4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1405\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 352\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = tok_ds.train_test_split(test_size=0.20, seed=0)\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1d093c9-84db-4a38-bb23-5f209a2cb615",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dds['train']\n",
    "eval_dataset = dds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59fffa3c-e855-406d-86c5-6dee5b1fb608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1405\n",
       "})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546fa1b-84ba-4dce-8a35-e1f2841996a4",
   "metadata": {},
   "source": [
    "## Training Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7979c64-feb8-4d75-b107-16718cd954f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70fed86-0107-4d2a-a470-cd2b2173e20f",
   "metadata": {},
   "source": [
    "Define batch size, number of epochs, and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "21b2b7a7-58bb-47ab-977a-d83046a066c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "epochs = 2\n",
    "lr = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee33c62-d230-4c76-bcf3-e7766a6023ab",
   "metadata": {},
   "source": [
    "Define our Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "72082cd5-e55e-4f36-9d4e-094700f7af53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    'outputs', \n",
    "    learning_rate=lr,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type='cosine',\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=bs, \n",
    "    per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, \n",
    "    weight_decay=0.01, \n",
    "    report_to='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d6a47b6-55c9-45ac-8a0a-946be781fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /afs/crc.nd.edu/user/p/painswor/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /afs/crc.nd.edu/user/p/painswor/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "false INTERNAL ASSERT FAILED at \"../c10/cuda/CUDAGraphsC10Utils.h\":73, please report a bug to PyTorch. Unknown CUDA graph CaptureStatus32583",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_944101/2648467019.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-cased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n\u001b[0m\u001b[1;32m      3\u001b[0m                   tokenizer=tokz)\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# Seed must be set before instantiating the model when using model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0menable_full_determinism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_determinism\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/trainer_utils.py\u001b[0m in \u001b[0;36mset_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# ^^ safe to call this function even if cuda is not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: false INTERNAL ASSERT FAILED at \"../c10/cuda/CUDAGraphsC10Utils.h\":73, please report a bug to PyTorch. Unknown CUDA graph CaptureStatus32583"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=7)\n",
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=tokz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2743e19-b292-4539-92cb-107c86f29a01",
   "metadata": {},
   "source": [
    "Create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6f36b42-0775-4331-adcf-506da497de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 2198\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 138\n",
      "  Number of trainable parameters = 108315655\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/parallel/parallel_apply.py\", line 64, in _worker\n    output = module(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/models/bert/modeling_bert.py\", line 1563, in forward\n    outputs = self.bert(\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/models/bert/modeling_bert.py\", line 1012, in forward\n    embedding_output = self.embeddings(\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/models/bert/modeling_bert.py\", line 238, in forward\n    embeddings = self.dropout(embeddings)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/dropout.py\", line 59, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/functional.py\", line 1252, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\nRuntimeError: philox_cuda_state for an unexpected CUDA generator used during capture. In regions captured by CUDA graphs, you may only use the default CUDA RNG generator on the device that's current when capture begins. If you need a non-default (user-supplied) generator, or a generator on another device, please file an issue.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_944101/2912127331.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 if (\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2569\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2571\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2572\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2573\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/parallel/parallel_apply.py\", line 64, in _worker\n    output = module(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/models/bert/modeling_bert.py\", line 1563, in forward\n    outputs = self.bert(\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/models/bert/modeling_bert.py\", line 1012, in forward\n    embedding_output = self.embeddings(\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/models/bert/modeling_bert.py\", line 238, in forward\n    embeddings = self.dropout(embeddings)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/modules/dropout.py\", line 59, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n  File \"/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/functional.py\", line 1252, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\nRuntimeError: philox_cuda_state for an unexpected CUDA generator used during capture. In regions captured by CUDA graphs, you may only use the default CUDA RNG generator on the device that's current when capture begins. If you need a non-default (user-supplied) generator, or a generator on another device, please file an issue.\n"
     ]
    }
   ],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf92e26-9df1-4089-84e3-e889f018bf82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c716ee5-ae86-4814-b3d7-a603507f9a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c18b1-51f5-4a02-8c35-b78b3225819c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e60ec1d2-78a5-4ace-9128-037cc17af7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(full_train_dataset, full_eval_dataset, full_val_dataset, full_heat_map, kfold):\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=7)\n",
    "\n",
    "    # removes unessecary columns\n",
    "    tf_train_dataset = full_train_dataset.remove_columns([\"text\"]).with_format(\"tensorflow\")\n",
    "    tf_eval_dataset = full_eval_dataset.remove_columns([\"text\"]).with_format(\"tensorflow\")\n",
    "    tf_val_dataset = full_val_dataset.remove_columns([\"text\"]).with_format(\"tensorflow\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "    # batches the datasets\n",
    "    train_features = {x: tf_train_dataset[x] for x in tokenizer.model_input_names}\n",
    "    train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_train_dataset[\"label\"]))\n",
    "    train_tf_dataset = train_tf_dataset.shuffle(len(tf_train_dataset)).batch(8)\n",
    "\n",
    "    eval_features = {x: tf_eval_dataset[x] for x in tokenizer.model_input_names}\n",
    "    eval_tf_dataset = tf.data.Dataset.from_tensor_slices((eval_features, tf_eval_dataset[\"label\"]))\n",
    "    eval_tf_dataset = eval_tf_dataset.batch(8)\n",
    "\n",
    "    val_features = {x: tf_val_dataset[x] for x in tokenizer.model_input_names}\n",
    "    val_tf_dataset = tf.data.Dataset.from_tensor_slices((val_features, tf_val_dataset[\"label\"]))\n",
    "    val_tf_dataset = val_tf_dataset.batch(8)\n",
    "\n",
    "    # compile and train the model\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    "    )\n",
    "\n",
    "    print(f'running model {kfold}')\n",
    "    history = model.fit(train_tf_dataset, validation_data=eval_tf_dataset, epochs=2)\n",
    "    print(f'finished model {kfold}')\n",
    "\n",
    "    # plot figures and save them on individual basis\n",
    "    acc_train = history.history['sparse_categorical_accuracy']\n",
    "    acc_val = history.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "    loss_train = history.history['loss']\n",
    "    loss_val = history.history['val_loss']\n",
    "\n",
    "    create_and_save_plots(acc_train, acc_val, 'Accuracy',kfold)\n",
    "    create_and_save_plots(loss_train, loss_val, 'Loss', kfold)\n",
    "\n",
    "    print(f'Evaulating model {kfold}')\n",
    "    # Evaluate the model on the test data using `evaluate`\n",
    "    results = model.evaluate(val_tf_dataset)\n",
    "\n",
    "    # Generate predictions (probabilities -- the output of the last layer)\n",
    "    # on new data using `predict`\n",
    "    predictions = model.predict(val_tf_dataset)\n",
    "\n",
    "    # get actual predictions from model.predict\n",
    "    actual_predictions = []\n",
    "    for prediction in predictions.logits:\n",
    "        max = -100\n",
    "        pred = -1\n",
    "    for index, val in enumerate(prediction):\n",
    "        if val > max:\n",
    "            max = val\n",
    "            pred = index\n",
    "    actual_predictions.append(pred)\n",
    "\n",
    "\n",
    "    # generate heat map + and update full heatmap\n",
    "    heat_map = np.zeros((7,7), dtype=float)\n",
    "    val_df = pd.read_csv(f'./split_datasets/val/FAA-{kfold}.csv')\n",
    "    correct = 0\n",
    "    for index, item in val_df.iterrows():\n",
    "        print(item['label'])\n",
    "        print(actual_predictions[index])\n",
    "\n",
    "    if item['label'] == actual_predictions[index]:\n",
    "        correct = correct + 1 \n",
    "    heat_map[6 - actual_predictions[index]][item['label']] = heat_map[ 6 - actual_predictions[index]][item['label']] + 1\n",
    "    # full\n",
    "    full_heat_map[6 - actual_predictions[index]][item['label']] = full_heat_map[ 6 - actual_predictions[index]][item['label']] + 1\n",
    "\n",
    "    print(correct/len(actual_predictions))\n",
    "    print(\"Correct based on my actual predictions: \", correct/len(actual_predictions))\n",
    "\n",
    "    # normalize heat map\n",
    "    normalize_save_heat_map(heat_map, kfold)\n",
    "\n",
    "    return history, results, predictions, heat_map, full_heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "79b46caf-f1aa-4d6c-98f0-74a47c42fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_plots(train, val, metric, kfold):\n",
    "    print(f'plotting {kfold}')  \n",
    "    epochs = range(1,3)\n",
    "\n",
    "    plt.plot(epochs, train, 'g', label=f'Training {metric}')\n",
    "    plt.plot(epochs, val, 'b', label=f'Validation {metric}')\n",
    "\n",
    "    plt.title(f'Training and Validation {metric}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(f'{metric}')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'./plots/FAA-test2{kfold}-{metric}.pdf')\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2c734c72-b30b-494e-9882-52c261bc4bf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (692751855.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_904740/692751855.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    total = 0\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def normalize_save_heat_map(heat_map, kfold):\n",
    "    print(f'heat map {kfold}')  \n",
    "    # normalize heat map\n",
    "    for index, category in enumerate(heat_map):\n",
    "    total = 0\n",
    "    for val in category:\n",
    "        total = total + val\n",
    "    for index_2, val in enumerate(category):\n",
    "        heat_map[index][index_2] = val / total\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11,9))\n",
    "    fig.set_tight_layout(True)\n",
    "    # color map\n",
    "    labels = ['II','ME','AU','AF','DE','EQ','AI']\n",
    "    y_labels = ['AI','EQ','DE','AF','AU','ME','II']\n",
    "\n",
    "    sb.heatmap(heat_map,cmap=\"Blues\",xticklabels=labels, yticklabels=y_labels, annot=True)\n",
    "    plt.savefig(f'./heatmaps-test2{kfold}.pdf')\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2433d8de-ca69-4726-ac76-20c6dda03eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_write_log_dict(index, log_dict):\n",
    "    acc_train = log_dict[1]['history'].history['sparse_categorical_accuracy']\n",
    "    acc_val = log_dict[1]['history'].history['val_sparse_categorical_accuracy']\n",
    "\n",
    "    loss_train = log_dict[1]['history'].history['loss']\n",
    "    loss_val = log_dict[1]['history'].history['val_loss']\n",
    "\n",
    "    heat_map = log_dict[1]['heat_map']\n",
    "    full_heat_map = log_dict[1]['full_heat_map']\n",
    "\n",
    "    temp_dict = {\n",
    "      index: {\n",
    "          'acc_train': acc_train,\n",
    "          'acc_val': acc_val,\n",
    "          'loss_val': loss_val,\n",
    "          'loss_train': loss_train,\n",
    "          'heat_map': heat_map,\n",
    "          'full_heat_map': full_heat_map\n",
    "      }\n",
    "    }\n",
    "\n",
    "    f = open('./log_dict_file_test.txt', 'a')\n",
    "    f.write(f'\\n\\n\\n{index}')\n",
    "    f.write(str(temp_dict))\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2599849d-a4d8-4ebd-893e-ed6276b9f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def once_run(index, log_dict, full_heat_map):\n",
    "    full_train_dataset, full_eval_dataset, full_val_dataset = tokenize_data(index)\n",
    "    history, results, predictions, heat_map, full_heat_map = train_evaluate(full_train_dataset, full_eval_dataset, full_val_dataset, full_heat_map, index)\n",
    "    log_dict[index] = {\n",
    "      'history': history,\n",
    "      'results': results,\n",
    "      'predictions': predictions,\n",
    "      'heat_map': heat_map,\n",
    "      'full_heat_map': full_heat_map\n",
    "    }\n",
    "    create_and_write_log_dict(index, log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb670619-7971-4046-9592-be73c2447f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_heat_map = np.zeros((7,7), dtype=float)\n",
    "log_dict = {}\n",
    "#for index in range(1,10):\n",
    "one_run(1, log_dict, full_heat_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
