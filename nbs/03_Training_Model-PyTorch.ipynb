{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38ee708c-071b-4e87-b170-8b9595face42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# This notebook is an outline for 10 fold cross validation neural network\n",
    "# Environment Setup\n",
    "#! pdm add transformers\n",
    "#! pdm add datasets\n",
    "#! pdm add keras==2.6.*\n",
    "#! pdm add torch==1.8.0 torchtext==0.9.0\n",
    "#! pdm add torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e159a8-6d54-4531-85bb-e37b68f6022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs', '/opt/anaconda3/lib/python39.zip', '/opt/anaconda3/lib/python3.9', '/opt/anaconda3/lib/python3.9/lib-dynload', '', '/afs/crc.nd.edu/user/p/painswor/.local/lib/python3.9/site-packages', '/opt/anaconda3/lib/python3.9/site-packages', '/opt/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/afs/crc.nd.edu/user/p/painswor/.ipython', '../__pypackages__/3.9/lib/']\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import sys\n",
    "sys.path.append('../__pypackages__/3.9/lib/')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa79e6c-d874-487d-9e07-a0a0281047f3",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59e5bd7-9a94-487f-9e49-1019a40738bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = '../data/cleaned-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858684b-d1da-404b-8ded-a0b22e1bda81",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff35846-b000-4c50-b86c-2bb5ce757098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 13:45:40.459128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from datasets import Dataset,DatasetDict,load_dataset\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438261d3-7ed3-427b-8b87-7f6ad8247847",
   "metadata": {},
   "source": [
    "Set kfold to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b149ba-671d-4e24-8cce-86bc3dcf7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e4aed-c2cb-4831-a668-cc6d3e758e81",
   "metadata": {},
   "source": [
    "Read kfold data into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4786dcac-76df-4cfa-a9b4-050747a9354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-40f85013f7ddcf10\n",
      "Found cached dataset csv (/afs/crc.nd.edu/user/p/painswor/.cache/huggingface/datasets/csv/default-40f85013f7ddcf10/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfa3b9a46174738b1231eed68a6185d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"csv\",data_files={'train': [f'{cleaned_data}/train/FAA-{kfold}.csv'], 'test': [f'{cleaned_data}/test/FAA-{kfold}.csv'],\n",
    "                                                'val': [f'{cleaned_data}/val/FAA-{kfold}.csv']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f01750-e09c-4253-a2a2-684e719b33e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1757\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 550\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 440\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100cc6a-17a2-4e11-8a05-219f2791a8d1",
   "metadata": {},
   "source": [
    "Tokenize text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3901a18d-594c-4ca9-82b3-60c74aea77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087bf120-a592-494e-8881-9a1cd07b6626",
   "metadata": {},
   "source": [
    "Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e6ba0f-e2d4-4e67-9605-147cc9dce617",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb41ad-7473-4699-8db0-3580baca8546",
   "metadata": {},
   "source": [
    "Tokenize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c182a10-dea3-4caa-be8c-aaeda824793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /afs/crc.nd.edu/user/p/painswor/.cache/huggingface/datasets/csv/default-40f85013f7ddcf10/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-7629b4b309ee0f0a.arrow\n",
      "Loading cached processed dataset at /afs/crc.nd.edu/user/p/painswor/.cache/huggingface/datasets/csv/default-40f85013f7ddcf10/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-b5bdf3e0fc6feea7.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c12c89cdb0425a84f3b4f7fd92f08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tok_func(x):\n",
    "    return tokz(x[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9cc496-a849-4543-914a-56b00a5bb1ca",
   "metadata": {},
   "source": [
    "Define datasets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da1d4d5a-4110-4495-baee-804c07ada651",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_eval_dataset = tokenized_datasets[\"test\"]\n",
    "full_val_dataset = tokenized_datasets[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135c94ef-1f8f-484a-9e6b-0894076b6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "298c5257-0a50-426f-b3c1-78a2aef48488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed495aa-18ad-4117-adbe-864c6bf4ebf7",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dae0117-7bb9-44c4-b452-200016fa6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef62b67b-6f65-4349-a443-68c7e939f7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc2cf2aa-15a4-4063-990c-4a7c0bdaadff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../output/runs\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "240002b8-631b-4de9-93a1-aa2e7cda076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_eval_dataset,\n",
    "    tokenizer=tokz,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64004735-a6e7-4780-be8b-5d9a72ea51bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1757\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 110\n",
      "  Number of trainable parameters = 108315655\n",
      "/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 01:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.919414</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.870662</td>\n",
       "      <td>0.732727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 550\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../output/runs/checkpoint-55\n",
      "Configuration saved in ../output/runs/checkpoint-55/config.json\n",
      "Model weights saved in ../output/runs/checkpoint-55/pytorch_model.bin\n",
      "tokenizer config file saved in ../output/runs/checkpoint-55/tokenizer_config.json\n",
      "Special tokens file saved in ../output/runs/checkpoint-55/special_tokens_map.json\n",
      "/afs/crc.nd.edu/group/TAI/Users/painswor/nbdev-framework-example/nbs/../__pypackages__/3.9/lib/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 550\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../output/runs/checkpoint-110\n",
      "Configuration saved in ../output/runs/checkpoint-110/config.json\n",
      "Model weights saved in ../output/runs/checkpoint-110/pytorch_model.bin\n",
      "tokenizer config file saved in ../output/runs/checkpoint-110/tokenizer_config.json\n",
      "Special tokens file saved in ../output/runs/checkpoint-110/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../output/runs/checkpoint-110 (score: 0.870662271976471).\n"
     ]
    }
   ],
   "source": [
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8da38cb1-4b47-4501-bedf-9ee2122afe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../model\n",
      "Configuration saved in ../model/config.json\n",
      "Model weights saved in ../model/pytorch_model.bin\n",
      "tokenizer config file saved in ../model/tokenizer_config.json\n",
      "Special tokens file saved in ../model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"../output/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5eab6e5-1b1a-4d40-ace8-26ff7fa60e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 440\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "747cae6e-38c7-4770-b857-2743ff85d300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=110, training_loss=0.7636618874289772, metrics={'train_runtime': 89.0243, 'train_samples_per_second': 39.472, 'train_steps_per_second': 1.236, 'total_flos': 924613755340800.0, 'train_loss': 0.7636618874289772, 'epoch': 2.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b6a2e-c057-46b3-a8a2-4646d6b5d6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
